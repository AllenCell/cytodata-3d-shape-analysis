{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25e6d913",
   "metadata": {},
   "source": [
    "# Shape Analysis in 3D\n",
    "\n",
    "0. Why analyze shape in biology?\n",
    "1. Fourier approximation \n",
    "2. Spherical harmonics\n",
    "3. Applied spherical harmonics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba31f0e",
   "metadata": {},
   "source": [
    "# Why do shape analysis in biology? \n",
    "\n",
    "<img src=\"resources/shapes_in_biology.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5515cced",
   "metadata": {},
   "source": [
    "## Shape \"type\" determines appropriate tool \n",
    "\n",
    "1. **2D contours** \n",
    "2. **Simple 3D shapes**\n",
    "3. Multi-component 3D shapes\n",
    "4. Shapes with underlying network topology\n",
    "5. Complex 3D shapes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14092a4",
   "metadata": {},
   "source": [
    "**What is shape?**\n",
    "\n",
    "D.G. Kendall (1984): \"what is left when the differences which can be attributed to translations, rotations, and dilatations have been quotiented out\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8c50bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyvista as pv\n",
    "pv.start_xvfb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff92edc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_nuc_mesh_1 = pv.read(\"resources/sample_nuc.vtk\")\n",
    "sample_nuc_mesh_2 = sample_nuc_mesh_1.copy()\n",
    "sample_nuc_mesh_2 = sample_nuc_mesh_2.translate((-150,0,20), inplace=True)\n",
    "sample_nuc_mesh_2 = sample_nuc_mesh_2.rotate_x(-30, inplace=True)\n",
    "sample_nuc_mesh_2 = sample_nuc_mesh_2.scale([1.5,1.5,1.5], inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "839f9265",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "294843.16911752906"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_nuc_mesh_1.volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef5ce3bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "995095.6915935851"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_nuc_mesh_2.volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cec04c7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fb692181c4e47a3b3610b69ce029374",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Renderer(camera=PerspectiveCamera(aspect=2.25, children=(DirectionalLight(intensity=0.25, position=(0.0, 0.0, …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotter = pv.Plotter(window_size=[900,400]) \n",
    "plotter.add_mesh(sample_nuc_mesh_1, color='lightgray')\n",
    "plotter.add_mesh(sample_nuc_mesh_2, color='lightgray')\n",
    "plotter.add_bounding_box(line_width=5, color='black')\n",
    "plotter.view_xz()\n",
    "plotter.camera.zoom(1.8)\n",
    "plotter.set_background('white')\n",
    "plotter.show(jupyter_backend='pythreejs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234e6432",
   "metadata": {},
   "source": [
    "**By Kendall's definition of shape, these two nuclei are equivalent!**\n",
    "\n",
    "## Practical implications\n",
    "\n",
    "There are many alternative definitions of shape. **Choose your definition** wisely and appropriately for the problem you're trying to solve.\n",
    "\n",
    "Methods for representing shape are generally ignorant to *our* definition of shape. We need to **do some preprocessing prior to encoding shape** e.g. nomalizing volume, aligning to a common axis, translating to a common origin. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4524bed3",
   "metadata": {},
   "source": [
    "## How to and why \"encode\" (parameterize) shape?\n",
    "\n",
    "In short, **parameterization** enables quantitative analyses by providing numbers representing shapes\n",
    "\n",
    "**Our image-based workflow looks like:**\n",
    "<img src=\"resources/param_workflow.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918a505a",
   "metadata": {},
   "source": [
    "## Introduction to Fourier Approximation: parameterization in 1D/2D:\n",
    "\n",
    "Fourier theory states that *any function can be represented by an infinite sum of sine and cosine terms*. In practice, we use a finite number of terms and obtain an approximation of our original function. \n",
    "\n",
    "When we approximate periodic functions, we *expand* the function into a Fourier series which looks like this: \n",
    "\n",
    "$y=A_o+A_1\\cos(\\frac{2πx}{L})+B_1 \\sin(\\frac{2πx}{L})+A_2 \\cos(\\frac{4πx}{L})+B_2 \\sin(\\frac{4πx}{L})+ \\space ...$\n",
    "\n",
    "Equivalently:\n",
    "\n",
    "$y= \\sum_{n=0}^N A_n \\cos(\\frac{2 \\pi n x}{L}) + \\sum_{n=0}^N B_n \\sin(\\frac{2 \\pi n x}{L})$\n",
    "\n",
    "- $L$ is half of the period of the function\n",
    "- $A_n$ and $B_n$ are coefficients we must calculate \n",
    "\n",
    "**How do we compute $A_n$ and $B_n$?**\n",
    "\n",
    "Given a function $f(x)$ which we want to approximate, we set up a minimization scheme by deriving $y$ w.r.t. $A_n$ and then w.r.t. $B_n$, setting $\\frac{\\partial E}{\\partial A_n}$ and $\\frac{\\partial E}{\\partial B_n}$ to zero. We arrive at the following equations:\n",
    "\n",
    "$A_n = \\frac{2}{L} \\int_{x_1}^{x_2} f(x) \\cos(\\frac{2 \\pi n x}{L})dx$\n",
    "\n",
    "$B_n = \\frac{2}{L} \\int_{x_1}^{x_2} f(x) \\sin(\\frac{2 \\pi n x}{L})dx$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49c40b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07efc0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 4\n",
    "n_points = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a6d653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define simple square waveform\n",
    "\n",
    "from scipy.signal import square \n",
    "\n",
    "x = np.linspace(0,L,n_points,endpoint=False)\n",
    "y = square(np.pi*x, duty=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7e9fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for computing Fourier coefficients using Simpson's integration technique\n",
    "\n",
    "from scipy.integrate import simps\n",
    "\n",
    "an = lambda n:2.0/L*simps(y*np.cos(2.*np.pi*n*x/L),x)\n",
    "bn = lambda n:2.0/L*simps(y*np.sin(2.*np.pi*n*x/L),x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e1a3b2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Interactive plot demonstrating Fourier series approximation for periodic functions\n",
    "\n",
    "from viz import get_square_wave_fig\n",
    "\n",
    "fig = get_square_wave_fig(x=x,\n",
    "                          y=y,\n",
    "                          L=L,\n",
    "                          an=an,\n",
    "                          bn=bn)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e56100",
   "metadata": {},
   "source": [
    "We can similarly use Fourier-based techniques to model closed 2D contours. For instance, consider a simple 2D closed contour: the square."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8aba7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define 2D square contour\n",
    "\n",
    "n_points = 32\n",
    "\n",
    "rq = np.linspace(-1,1-2.0/n_points, n_points).tolist()\n",
    "lq = (-np.linspace(-1,1-2.0/n_points, n_points)).tolist()\n",
    "x = rq + [1]*n_points + lq + [-1]*n_points\n",
    "y = [-1]*n_points + rq + [1]*n_points + lq\n",
    "x = np.array(x + [x[0]])\n",
    "y = np.array(y + [y[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d1e5cb",
   "metadata": {},
   "source": [
    "<img src=\"resources/square_cartesian_vs_polar.png\" width=\"70%\"/>\n",
    "\n",
    "**By mapping the square into polar coordinates, we can represent it with a 1-parameter function $r(\\theta)$ w.r.t. $\\theta$ rather than w.r.t. $x-$ and $y-$, which requires a 2-parameter function**\n",
    "- $r(\\theta)$ maps the distance from each point on the contour to the origin. \n",
    "\n",
    "Thus we can do a Fourier expansion of $r(\\theta)$:\n",
    "\n",
    "$r(\\theta) =  \\frac{a_0}{2} + \\sum_{n=1}^{\\infty}(A_n \\cos n \\theta + B_n \\sin n \\theta)$\n",
    "\n",
    "where the Fourier coeffcients are:\n",
    "\n",
    "$A_n = \\frac{1}{\\pi} \\int_{-\\pi}^{\\pi} r(\\theta) \\cos n \\theta d \\theta$\n",
    "\n",
    "$B_n = \\frac{1}{\\pi} \\int_{-\\pi}^{\\pi} r(\\theta) \\sin n \\theta d \\theta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984d931c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to polar coordinates\n",
    "r = np.sqrt(x**2+y**2)\n",
    "theta = np.arctan2(y,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0977c0b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Interactive plot demonstrating 1-param Fourier expansion of 2D square\n",
    "\n",
    "from viz import get_one_param_polar_fig\n",
    "\n",
    "fig = get_one_param_polar_fig(theta, r, x, y)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6551d7",
   "metadata": {},
   "source": [
    "This Fourier basis representation is not without limitations. Shown below is a simple 2D \"C\" contour that cannot be described by Fourier decomposition as in above. \n",
    "\n",
    "<img src=\"resources/C_contour_approximation.png\"/>\n",
    "\n",
    "**Why?**\n",
    "- the radius does not cross the contour for some $\\theta$ \n",
    "- some $\\theta$ values map to more than one $r$ value. \n",
    "\n",
    "Note: in this case, these issues cannot be resolved by moving the origin\n",
    "\n",
    "As a solution, we can use an extended Fourier method by Kuhl and Giardina (1982): the *elliptical Fourier variant*. Now we **use two parametric functions $x(t)$ and $y(t)$** s.t. $t$ is *arc length* relative to an origin on the contour rather than an angle relative to the origin ($\\theta$), as in above. The simple idea is that $x(t)$ and $y(t)$ correspond to the $x-$ and $y-$Cartesian coordinates of the 2D contour.\n",
    "\n",
    "Now we have 4 sets of coefficients:\n",
    "\n",
    "$x(t) = \\frac{A_0}{2} + \\sum_{n=1}^{\\infty}(A_n \\cos n t + B_n \\sin n t)$\n",
    "\n",
    "$y(t) = \\frac{C_0}{2} + \\sum_{n=1}^{\\infty}(C_n \\cos n t + D_n \\sin n t)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707c81e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \"C\" contour in Cartesian coordinates\n",
    "n_terms = 25\n",
    "n_points = 100\n",
    "\n",
    "xy = np.array([[-1.0,1.0], [0,1.0], [1.0,1.0], \n",
    "               [1.0,0.75], [0,0.75], [-0.75,0.75], \n",
    "               [-0.75,0], [-0.75,-0.75], [0,-0.75], \n",
    "               [1.0,-0.75], [1.0,-1.0], [0,-1.0],\n",
    "               [-1.0,-1.0], [-1.0,0], [-1.0,1.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a425c42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pyefd\n",
    "\n",
    "coeffs = pyefd.elliptic_fourier_descriptors(xy, order=n_terms)\n",
    "a0, c0 = pyefd.calculate_dc_coefficients(xy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a3307c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Interactive plot demonstrating 2-param Fourier expansion of 2D \"C\"\n",
    "\n",
    "from viz import get_two_param_2d_fig\n",
    "\n",
    "fig = get_two_param_2d_fig(coeffs, a0, c0, \n",
    "                           xy, \n",
    "                           n_points, \n",
    "                           n_terms)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ecbdc2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from viz import get_two_param_coeff_table\n",
    "\n",
    "coeff_table = get_two_param_coeff_table(xy)\n",
    "coeff_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810a617a",
   "metadata": {},
   "source": [
    "Remember what we said about preprocessing prior to encoding shape?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc852b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rotate \"C\" contour 90 degrees counter-clockwise\n",
    "xy_rotated = np.vstack([-xy[:,1], xy[:,0]]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c262fc5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from viz import get_rotate_2d_fig\n",
    "\n",
    "fig = get_rotate_2d_fig(xy, xy_rotated)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab55580",
   "metadata": {},
   "source": [
    "**Is a \"C\" rotated 90 degrees still a \"C\"?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f47acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "coeffs = pyefd.elliptic_fourier_descriptors(xy, order=5)\n",
    "coeffs_rot = pyefd.elliptic_fourier_descriptors(xy_rotated, order=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c69a909",
   "metadata": {},
   "outputs": [],
   "source": [
    "coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f5e4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "coeffs_rot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a7e3a5",
   "metadata": {},
   "source": [
    "## Fourier-based workflow for 2D analysis\n",
    "\n",
    "<img src=\"resources/fourier_workflow.png\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527e0256",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_2d_contour = np.load(\"resources/cell_contour.npy\")\n",
    "cell_2d_contour.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7de87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "coeffs = pyefd.elliptic_fourier_descriptors(cell_2d_contour, order=n_terms)\n",
    "a0, c0 = pyefd.calculate_dc_coefficients(cell_2d_contour)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60adf122",
   "metadata": {},
   "source": [
    "How do we know when our reconstruction is \"good\"? We use **reconstruction error**! This measures the difference between the reconstructed contour and the original. Here we match nearest points and compute a mean squared error. There are many other options. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fd1bdb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Interactive plot demonstrating 2-param Fourier expansion of 2D cell contour\n",
    "\n",
    "fig = get_two_param_2d_fig(coeffs, a0, c0, \n",
    "                           cell_2d_contour, \n",
    "                           n_points, \n",
    "                           n_terms, \n",
    "                           show_recon_err=True,\n",
    "                           set_aspect_ratio=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228726a2",
   "metadata": {},
   "source": [
    "# Intro to Spherical Harmonics\n",
    "\n",
    "Spherical harmonics are special functions defined on the sphere. Using spherical harmonics is one of a few techniques we can use to efficiently represent 3D shapes (surfaces). **The way we can use spherical harmonics is analogous to the way we used the Fourier Transform to approximate functions**. The theory of spherical harmonics states *any spherical function $f(\\theta, \\phi)$ can be decomposed as the sum of its harmonics*:\n",
    "\n",
    "$f(\\theta, \\phi) = \\sum_{l=0}^{\\infty} \\sum_{m=-l}^{m=l} a_{lm} Y_l^m(\\theta, \\phi)$\n",
    "\n",
    "A spherical harmonic representation is composed of the coefficients associated with these functions. \n",
    "\n",
    "\n",
    "<img src=\"resources/shcoeff_workflow.png\"/>\n",
    "\n",
    "Practical notes\n",
    "- $\\text{L}_{\\text{max}}$ is analogous to \"number of terms\"\n",
    "- Spherical harmonics are most appropriate in our domain to describe relatively simple, closed forms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54fa3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aicsimageio import AICSImage\n",
    "\n",
    "sample_cell_img = AICSImage(\"resources/416089.tiff\").data.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fd7dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Get reconstructed meshes and reconstruction error for Lmax=1-16\n",
    "\n",
    "from utils import get_mesh_from_series\n",
    "from aicsshparam import shparam, shtools\n",
    "\n",
    "MAX_LMAX = 16\n",
    "recon_errors = []\n",
    "recon_meshes = []\n",
    "for l in range(1,MAX_LMAX+1):\n",
    "    (coeffs, grid_rec), (image_, mesh, grid, transform) = shparam.get_shcoeffs(image=sample_cell_img[0,:,:,:], \n",
    "                                                                              lmax=l)\n",
    "    shcoeffs_mesh = get_mesh_from_series(coeffs,l)\n",
    "    mse = shtools.get_reconstruction_error(grid, grid_rec)\n",
    "    recon_errors.append(mse)\n",
    "    recon_meshes.append(shcoeffs_mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90dff3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_mesh, _, _ = shtools.get_mesh_from_image(sample_cell_img[0,:,:,:])\n",
    "gt_mesh = pv.wrap(gt_mesh)\n",
    "gt_mesh = gt_mesh.translate((-200, 0, 0), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c696899d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Interactive plot demonstrating reconstruction via SH coeffs\n",
    "\n",
    "from viz import interactive_reconstruction_plot\n",
    "\n",
    "interactive_reconstruction_plot(recon_errors, recon_meshes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89528275",
   "metadata": {},
   "source": [
    "# Using spherical harmonics on toy dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef8f050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create toy shape dataset s.t. each shape has volume~=1.0\n",
    "base_cube = pv.Cube()\n",
    "base_cylinder = pv.Cylinder(radius=0.564)\n",
    "base_cone = pv.Cone(height=2.0, radius=0.7596)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a99b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_cone.volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0e102c",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_cube.volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff95f63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_cylinder.volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfa2cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter = pv.Plotter(window_size=[900,400], shape=(1,3)) \n",
    "plotter.subplot(0,0)\n",
    "plotter.add_mesh(base_cube, color='lightgray', show_edges=True)\n",
    "plotter.subplot(0,1)\n",
    "plotter.add_mesh(base_cylinder, color='lightgray', show_edges=True)\n",
    "plotter.set_background('white')\n",
    "plotter.subplot(0,2)\n",
    "plotter.add_mesh(base_cone, color='lightgray', show_edges=True)\n",
    "plotter.set_background('white')\n",
    "plotter.show(jupyter_backend='pythreejs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097c2fef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Convert meshes into 3D images and compute corresponding SH coeffs\n",
    "\n",
    "from utils import get_image_from_polydata\n",
    "\n",
    "LMAX = 16\n",
    "\n",
    "base_cube_im = get_image_from_polydata(base_cube)\n",
    "(base_cube_shcoeffs, _), (_, _, _, _) = shparam.get_shcoeffs(base_cube_im, \\\n",
    "                                                             LMAX)\n",
    "base_cube_shcoeffs_mesh = get_mesh_from_series(base_cube_shcoeffs,LMAX)\n",
    "\n",
    "base_cyl_im = get_image_from_polydata(base_cylinder)\n",
    "(base_cyl_shcoeffs, _), (_, _, _, _) = shparam.get_shcoeffs(base_cyl_im, \\\n",
    "                                                             LMAX)\n",
    "base_cyl_shcoeffs_mesh = get_mesh_from_series(base_cyl_shcoeffs,LMAX)\n",
    "\n",
    "base_cone_im = get_image_from_polydata(base_cone)\n",
    "(base_cone_shcoeffs, _), (_, _, _, _) = shparam.get_shcoeffs(base_cone_im, \\\n",
    "                                                             LMAX)\n",
    "base_cone_shcoeffs_mesh = get_mesh_from_series(base_cone_shcoeffs,LMAX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57ea70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from viz import get_recon_mesh_plotter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c302618",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = get_recon_mesh_plotter(base_cube, base_cube_shcoeffs_mesh)\n",
    "pl.show(jupyter_backend='pythreejs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c2f8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = get_recon_mesh_plotter(base_cylinder, base_cyl_shcoeffs_mesh)\n",
    "pl.show(jupyter_backend='pythreejs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b63395",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pl = get_recon_mesh_plotter(base_cone, base_cone_shcoeffs_mesh)\n",
    "pl.show(jupyter_backend='pythreejs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f108e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_cube_im.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc2d4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.power(base_cube_im.shape[0],3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535b4380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct toy dataset of shapes by applying Gaussian noise to each base shape's SH coeffs\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "N_EXAMPLES = 20\n",
    "N_COEFFS = len(base_cube_shcoeffs)\n",
    "\n",
    "np.random.seed(20)\n",
    "cube_noise = np.random.normal(0.0, 0.1, [N_COEFFS * 20])\n",
    "\n",
    "np.random.seed(21)\n",
    "cyl_noise = np.random.normal(0.0, 0.1, [N_COEFFS * 20])\n",
    "\n",
    "np.random.seed(22)\n",
    "cone_noise = np.random.normal(0.0, 0.1, [N_COEFFS * 20])\n",
    "\n",
    "cubes = [(cube_noise[i*N_COEFFS:i*N_COEFFS+N_COEFFS] + pd.Series(base_cube_shcoeffs)).to_numpy() for i in range(0,N_EXAMPLES)]\n",
    "cylinders = [(cyl_noise[i*N_COEFFS:i*N_COEFFS+N_COEFFS] + pd.Series(base_cyl_shcoeffs)).to_numpy() for i in range(0,N_EXAMPLES)]\n",
    "cones = [(cone_noise[i*N_COEFFS:i*N_COEFFS+N_COEFFS] + pd.Series(base_cone_shcoeffs)).to_numpy() for i in range(0,N_EXAMPLES)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f8a0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_shapes = np.vstack([cubes, cylinders, cones])\n",
    "labels = [\"cube\"] * 20 + [\"cylinder\"] * 20 + [\"cone\"] * 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a9ff5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_shapes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1639049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do PCA on SH coeffs \n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(2)\n",
    "pca = pca.fit(all_shapes)\n",
    "axes = pca.transform(all_shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc534034",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from viz import get_pca_result_fig\n",
    "\n",
    "fig = get_pca_result_fig(axes, labels)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a5f1c6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pca_df = pd.DataFrame({\"PC1\":axes[:,0], \"PC2\":axes[:,1], \"shape\":labels})\n",
    "pca_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1d9b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get centroids in PCA space\n",
    "\n",
    "cube_centroid = pca_df[pca_df[\"shape\"] == \"cube\"].mean().values\n",
    "cone_centroid = pca_df[pca_df[\"shape\"] == \"cone\"].mean().values\n",
    "\n",
    "x = np.vstack([cube_centroid, cone_centroid])[:,0]\n",
    "y = np.vstack([cube_centroid, cone_centroid])[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf812f80",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Latent walk in PCA space: get equally spaced points along a line connecting our centroids\n",
    "\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "n_steps = 5\n",
    "distance = np.cumsum(np.sqrt(np.ediff1d(x, to_begin=0)**2 + np.ediff1d(y, to_begin=0)**2))\n",
    "distance = distance/distance[-1]\n",
    "fx, fy = interp1d(distance, x), interp1d(distance, y)\n",
    "alpha = np.linspace(0, 1, n_steps)\n",
    "latent_line_x, latent_line_y = fx(alpha), fy(alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1e3396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize latent walk\n",
    "\n",
    "from viz import get_pca_clust_latent_walk_fig\n",
    "\n",
    "fig = get_pca_clust_latent_walk_fig(axes, latent_line_x, latent_line_y, labels)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3edc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get meshes corresponding to points along latent axis\n",
    "\n",
    "latent_walk_meshes = []\n",
    "for i in range(n_steps):\n",
    "    shcoeffs_i = pca.inverse_transform(np.array([latent_line_x[i],latent_line_y[i]]).reshape(1,2))\n",
    "    shcoeffs_dict = dict(zip(list(base_cube_shcoeffs.keys()),list(shcoeffs_i.squeeze())))\n",
    "    recon_mesh = get_mesh_from_series(shcoeffs_dict,16)\n",
    "    latent_walk_meshes.append(recon_mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc7ee68",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = pv.Plotter(window_size=[900,300], shape=(1,5))\n",
    "pl.set_background(\"white\")\n",
    "\n",
    "for i in range(n_steps):\n",
    "    pl.subplot(0,i)\n",
    "    pl.add_mesh(latent_walk_meshes[i], color=\"lightgrey\")\n",
    "    pl.add_title(f\"Latent index {i}\", font_size=8)\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be07476f",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In summary, we covered using the Fourier and spherical harmonics expansions for parameterizing 2D and 3D shape, respectively. \n",
    "\n",
    "To learn more about how we are using some of these concepts to understand intracellular organization in human stem cells, see our paper *Robust integrated intracellular organization of the human iPS cell: where, how much, and how variable* \n",
    "<img src=\"resources/variance_paper_fig.png\" width=\"80%\"/>\n",
    "- https://www.biorxiv.org/content/10.1101/2020.12.08.415562v2.full\n",
    "\n",
    "Resources\n",
    "- This workshop: https://github.com/AllenCell/cytodata-3d-shape-analysis\n",
    "- Our spherical harmonics parameterization library: https://github.com/AllenCell/aics-shparam\n",
    "- Our microscopy image reading/writing library: https://github.com/AllenCellModeling/aicsimageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91aa950",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
